<!doctype html>
<html lang="en-us">
  <head>
    
    <script>
      MathJax = {
        tex: {
          inlineMath: [["$", "$"]],
        },
        displayMath: [
          ["$$", "$$"],
          ["\[\[", "\]\]"],
        ],
        svg: {
          fontCache: "global",
        },
      };
    </script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    ></script>
    
    <title>如何用梯度下降法训练一个简单的线性模型 // 金谷风的博客</title>
    <link rel="shortcut icon" href="/favicon.ico" />
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.123.3">
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="Gufeng Jin" />
    <meta name="description" content="" />
    <link rel="stylesheet" href="/css/main.min.5b1fcc8902588589c4767187402a3c29f8b8d7a6fdef6d9f8f77045bb0d14fee.css" />
    

    
    <meta name="twitter:card" content="summary"/><meta name="twitter:title" content="如何用梯度下降法训练一个简单的线性模型"/>
<meta name="twitter:description" content="如何用梯度下降法训练一个简单的线性模型 数学模型是什么？ 数学模型能够从数据中学习并进行预测或决策。这些模型可以用于解决各种问题，包括分类 Classification, 回归 Regression等。模型通常被用来发现数据中的模式和关联，从而进行预测或做出决策。
模型通常包含输入值和输出值。输入值 Input通常是一组特征或属性，用来描述数据的各个方面。输出值 Output则是模型根据输入值进行预测或分类的结果。
在监督学习 Supervised learning中，模型通过学习输入值和对应的输出值之间的关系来进行预测或分类。这些输入值和输出值通常被组织成训练集 Training set和验证集 Validation set，模型通过训练集学习输入和输出之间的映射关系。然后使用验证集来评估模型的性能，以便更好地了解模型在未见过的数据上的表现。通过与训练集分开的独立数据进行评估，可以更客观地判断模型的泛化能力，即模型对未知数据的适应能力。一旦训练完成，模型就可以用来对新的输入值进行预测或分类。
在 无监督学习 Unsupervised learning中，模型不需要标记的输出值，而是试图发现数据中的结构或模式。输入值被用来描述数据，而模型则尝试根据这些输入值发现数据的内在结构或者进行聚类等任务。
如何用梯度下降法 Gradient Descent Method训练一个简单的线性模型？ 先来看下如何训练监督学习类问题，我们将用梯度下降法训练一个简单的线性模型。
首先，我们需要准备包含输入值和对应输出值（标签）的数据集。在下面代码中例子里输入值是 $x = [1, 2, 3, 4]$，输出值是 $y = [2, 3, 4, 5]$。
第二步选择模型，在这个例子中我们选择线性模型， $y_{pred} = ax &#43; b$, 其中x是输入值，$y_{pred}$是预测值，而a和b是模型的两个参数。
第三步定义损失函数，我们的目标是模型能根据输入的$x$准确的输出$y$的值，所以我们需要预测值尽可能的等于输出值，也就是$y-y_{pred}$ 尽可能接近零。我们的损失函数是均方误差（MSE），定义如下： $$ \frac{1}{n}\sum_{i=1}^{n}\left ( y_{i}-(ax_{i}&#43;b) \right )^{2} $$ 其中，$n$ 是样本数量，$y_i$ 是实际标签，$x_i$ 是对应的特征值。我们的目标就是通过优化算法修改参数 (a,b) 让损失函数尽可能小。
第四部选择优化算法，我们选择梯度下降法训练。梯度下降法包含四个步骤，
前向传播（Forward Propagation）：使用当前的参数值对训练数据进行前向传播，得到模型的预测输出。
计算损失（Compute Loss）：将模型的预测输出与真实标签进行比较，计算损失函数的值。
反向传播（Backward Propagation）：通过损失函数，计算模型参数的梯度，即损失函数对每个参数的偏导数。
参数更新（Update Parameters）：根据梯度下降或其他优化算法，沿着梯度的反方向更新参数，使损失函数减小。
我们来计算下在这个例子中参数的梯度是什么，损失函数为 $\frac{1}{n}\sum_{i=1}^{n}\left ( y_{i}-(ax_{i}&#43;b) \right )^{2}$。 对a的偏导数为 $\frac{\partial \text{MSE}}{\partial a}$ , 这个式子可以分解为$\frac{\partial \text{MSE}}{\partial y_{pred}} \cdot \frac{\partial y_{pred}}{\partial a} $。"/>

    <meta property="og:title" content="如何用梯度下降法训练一个简单的线性模型" />
<meta property="og:description" content="如何用梯度下降法训练一个简单的线性模型 数学模型是什么？ 数学模型能够从数据中学习并进行预测或决策。这些模型可以用于解决各种问题，包括分类 Classification, 回归 Regression等。模型通常被用来发现数据中的模式和关联，从而进行预测或做出决策。
模型通常包含输入值和输出值。输入值 Input通常是一组特征或属性，用来描述数据的各个方面。输出值 Output则是模型根据输入值进行预测或分类的结果。
在监督学习 Supervised learning中，模型通过学习输入值和对应的输出值之间的关系来进行预测或分类。这些输入值和输出值通常被组织成训练集 Training set和验证集 Validation set，模型通过训练集学习输入和输出之间的映射关系。然后使用验证集来评估模型的性能，以便更好地了解模型在未见过的数据上的表现。通过与训练集分开的独立数据进行评估，可以更客观地判断模型的泛化能力，即模型对未知数据的适应能力。一旦训练完成，模型就可以用来对新的输入值进行预测或分类。
在 无监督学习 Unsupervised learning中，模型不需要标记的输出值，而是试图发现数据中的结构或模式。输入值被用来描述数据，而模型则尝试根据这些输入值发现数据的内在结构或者进行聚类等任务。
如何用梯度下降法 Gradient Descent Method训练一个简单的线性模型？ 先来看下如何训练监督学习类问题，我们将用梯度下降法训练一个简单的线性模型。
首先，我们需要准备包含输入值和对应输出值（标签）的数据集。在下面代码中例子里输入值是 $x = [1, 2, 3, 4]$，输出值是 $y = [2, 3, 4, 5]$。
第二步选择模型，在这个例子中我们选择线性模型， $y_{pred} = ax &#43; b$, 其中x是输入值，$y_{pred}$是预测值，而a和b是模型的两个参数。
第三步定义损失函数，我们的目标是模型能根据输入的$x$准确的输出$y$的值，所以我们需要预测值尽可能的等于输出值，也就是$y-y_{pred}$ 尽可能接近零。我们的损失函数是均方误差（MSE），定义如下： $$ \frac{1}{n}\sum_{i=1}^{n}\left ( y_{i}-(ax_{i}&#43;b) \right )^{2} $$ 其中，$n$ 是样本数量，$y_i$ 是实际标签，$x_i$ 是对应的特征值。我们的目标就是通过优化算法修改参数 (a,b) 让损失函数尽可能小。
第四部选择优化算法，我们选择梯度下降法训练。梯度下降法包含四个步骤，
前向传播（Forward Propagation）：使用当前的参数值对训练数据进行前向传播，得到模型的预测输出。
计算损失（Compute Loss）：将模型的预测输出与真实标签进行比较，计算损失函数的值。
反向传播（Backward Propagation）：通过损失函数，计算模型参数的梯度，即损失函数对每个参数的偏导数。
参数更新（Update Parameters）：根据梯度下降或其他优化算法，沿着梯度的反方向更新参数，使损失函数减小。
我们来计算下在这个例子中参数的梯度是什么，损失函数为 $\frac{1}{n}\sum_{i=1}^{n}\left ( y_{i}-(ax_{i}&#43;b) \right )^{2}$。 对a的偏导数为 $\frac{\partial \text{MSE}}{\partial a}$ , 这个式子可以分解为$\frac{\partial \text{MSE}}{\partial y_{pred}} \cdot \frac{\partial y_{pred}}{\partial a} $。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://gufengjin770.github.io/post/deeplearning1/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2024-02-28T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-02-28T00:00:00+00:00" />



  </head>
  <body>
    <header class="app-header">
      <a href="https://gufengjin770.github.io/"><img class="app-header-avatar" src="/image1.jpg" alt="Gufeng Jin" /></a>
      <span class="app-header-title">金谷风的博客</span>
      <nav class="app-header-menu">
          <a class="app-header-menu-item" href="/">Home</a>
             - 
          
          <a class="app-header-menu-item" href="/tags/">Tags</a>
             - 
          
          <a class="app-header-menu-item" href="/about/">About</a>
      </nav>
      <p>兢兢以强</p>
      <div class="app-header-social">
        
          <a href="https://github.com/gufengjin770" target="_blank" rel="noreferrer noopener me">
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-github">
  <title>Github</title>
  <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path>
</svg>
          </a>
        
          <a href="mailto:gufengjin770@gmail.com" target="_blank" rel="noreferrer noopener me">
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-mail">
  <title>E-mail</title>
  <path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"></path><polyline points="22,6 12,13 2,6"></polyline>
</svg>
          </a>
        
      </div>
    </header>
    <main class="app-container">
      
  <article class="post">
    <header class="post-header">
      <h1 class ="post-title">如何用梯度下降法训练一个简单的线性模型</h1>
      <div class="post-meta">
        <div>
          <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar">
  <title>calendar</title>
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line>
</svg>
          Feb 28, 2024
        </div>
        <div>
          <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock">
  <title>clock</title>
  <circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline>
</svg>
          2 min read
        </div>
        <div>
          <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tag">
  <title>tag</title>
  <path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7.01" y2="7"></line>
</svg>
              <a class="tag" href="https://gufengjin770.github.io/tags/blog/">Blog</a>
        </div>
      </div>
    </header>
    <div class="post-content">
      <h3 id="如何用梯度下降法训练一个简单的线性模型">如何用梯度下降法训练一个简单的线性模型</h3>
<h4 id="数学模型是什么">数学模型是什么？</h4>
<p>数学模型能够从数据中学习并进行预测或决策。这些模型可以用于解决各种问题，包括<strong>分类 Classification</strong>, <strong>回归 Regression</strong>等。模型通常被用来发现数据中的模式和关联，从而进行预测或做出决策。</p>
<p>模型通常包含输入值和输出值。<strong>输入值 Input</strong>通常是一组特征或属性，用来描述数据的各个方面。<strong>输出值 Output</strong>则是模型根据输入值进行预测或分类的结果。</p>
<p>在<strong>监督学习 Supervised learning</strong>中，模型通过学习输入值和对应的输出值之间的关系来进行预测或分类。这些输入值和输出值通常被组织成<strong>训练集 Training set</strong>和<strong>验证集 Validation set</strong>，模型通过训练集学习输入和输出之间的映射关系。然后使用验证集来评估模型的性能，以便更好地了解模型在未见过的数据上的表现。通过与训练集分开的独立数据进行评估，可以更客观地判断模型的泛化能力，即模型对未知数据的适应能力。一旦训练完成，模型就可以用来对新的输入值进行预测或分类。</p>
<p>在 <strong>无监督学习 Unsupervised learning</strong>中，模型不需要标记的输出值，而是试图发现数据中的结构或模式。输入值被用来描述数据，而模型则尝试根据这些输入值发现数据的内在结构或者进行聚类等任务。</p>
<h4 id="如何用梯度下降法-gradient-descent-method训练一个简单的线性模型">如何用<strong>梯度下降法 Gradient Descent Method</strong>训练一个简单的线性模型？</h4>
<p>先来看下如何训练监督学习类问题，我们将用梯度下降法训练一个简单的线性模型。</p>
<p>首先，我们需要准备包含输入值和对应输出值（标签）的数据集。在下面代码中例子里输入值是 $x = [1, 2, 3, 4]$，输出值是 $y = [2, 3, 4, 5]$。</p>
<p>第二步选择模型，在这个例子中我们选择线性模型， $y_{pred} = ax + b$, 其中x是输入值，$y_{pred}$是预测值，而a和b是模型的两个参数。</p>
<p>第三步定义损失函数，我们的目标是模型能根据输入的$x$准确的输出$y$的值，所以我们需要预测值尽可能的等于输出值，也就是$y-y_{pred}$ 尽可能接近零。我们的损失函数是均方误差（MSE），定义如下：
$$
\frac{1}{n}\sum_{i=1}^{n}\left ( y_{i}-(ax_{i}+b) \right )^{2}
$$
其中，$n$ 是样本数量，$y_i$ 是实际标签，$x_i$ 是对应的特征值。我们的目标就是通过优化算法修改参数 (a,b) 让损失函数尽可能小。</p>
<p>第四部选择优化算法，我们选择梯度下降法训练。梯度下降法包含四个步骤，</p>
<ol>
<li>
<p><strong>前向传播（Forward Propagation）</strong>：使用当前的参数值对训练数据进行前向传播，得到模型的预测输出。</p>
</li>
<li>
<p><strong>计算损失（Compute Loss）</strong>：将模型的预测输出与真实标签进行比较，计算损失函数的值。</p>
</li>
<li>
<p><strong>反向传播（Backward Propagation）</strong>：通过损失函数，计算模型参数的梯度，即损失函数对每个参数的偏导数。</p>
</li>
<li>
<p><strong>参数更新（Update Parameters）</strong>：根据梯度下降或其他优化算法，沿着梯度的反方向更新参数，使损失函数减小。</p>
</li>
</ol>
<p>我们来计算下在这个例子中参数的梯度是什么，损失函数为 $\frac{1}{n}\sum_{i=1}^{n}\left ( y_{i}-(ax_{i}+b) \right )^{2}$。 对a的偏导数为 $\frac{\partial \text{MSE}}{\partial a}$ , 这个式子可以分解为$\frac{\partial \text{MSE}}{\partial y_{pred}} \cdot \frac{\partial y_{pred}}{\partial a} $。</p>
<p>$\frac{\partial \text{MSE}}{\partial y_{pred}} = -\frac{2}{n}\sum_{i=1}^{n}\left ( y_{i}-(ax_{i}+b) \right )$</p>
<p>$\frac{\partial y_{pred}}{\partial a} = x_{i}$</p>
<p>损失函数对参数a的偏导数可以写成$\frac{\partial \text{MSE}}{\partial a}= -\frac{2}{n}x_{i}\sum_{i=1}^{n}\left ( y_{i}-y_{pred}\right )$</p>
<p>同样的方法求出b的偏导数$\frac{\partial \text{MSE}}{\partial b}= -\frac{2}{n}\sum_{i=1}^{n}\left ( y_{i}-y_{pred}\right )$</p>
<p>求出梯度后用把梯度代入到参数更新的公式中就行$a=a - \eta \frac{\partial \text{MSE}}{\partial a}$, $\eta$是<strong>学习率</strong>。</p>
<p>这个过程会在整个训练数据集上重复多次（称为一个<strong>epoch</strong>），直到达到预定的停止条件，如达到最大迭代次数或损失收敛到某个阈值。</p>
<p>接下来我们用python实现这个过程看下效果。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> random
</span></span><span style="display:flex;"><span>a <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>b <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>learning_rate <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.01</span>
</span></span><span style="display:flex;"><span>epochs <span style="color:#f92672">=</span> <span style="color:#ae81ff">1000</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 定义样本数据</span>
</span></span><span style="display:flex;"><span>x <span style="color:#f92672">=</span> [<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>]
</span></span><span style="display:flex;"><span>y <span style="color:#f92672">=</span> [<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">5</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 训练模型</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(epochs):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 初始化梯度</span>
</span></span><span style="display:flex;"><span>    grad_a <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    grad_b <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 计算所有样本的梯度</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(x)):
</span></span><span style="display:flex;"><span>        x_i <span style="color:#f92672">=</span> x[i]
</span></span><span style="display:flex;"><span>        y_i <span style="color:#f92672">=</span> y[i]
</span></span><span style="display:flex;"><span>        y_pred <span style="color:#f92672">=</span> a <span style="color:#f92672">*</span> x_i <span style="color:#f92672">+</span> b
</span></span><span style="display:flex;"><span>        grad_a <span style="color:#f92672">+=</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> x_i <span style="color:#f92672">*</span> (y_i <span style="color:#f92672">-</span> y_pred)
</span></span><span style="display:flex;"><span>        grad_b <span style="color:#f92672">+=</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> (y_i <span style="color:#f92672">-</span> y_pred)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 对所有样本的梯度求平均</span>
</span></span><span style="display:flex;"><span>    grad_a <span style="color:#f92672">/=</span> len(x)
</span></span><span style="display:flex;"><span>    grad_b <span style="color:#f92672">/=</span> len(x)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 更新参数</span>
</span></span><span style="display:flex;"><span>    a <span style="color:#f92672">-=</span> learning_rate <span style="color:#f92672">*</span> grad_a
</span></span><span style="display:flex;"><span>    b <span style="color:#f92672">-=</span> learning_rate <span style="color:#f92672">*</span> grad_b
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 打印最终参数</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Final parameters: a =&#34;</span>, a, <span style="color:#e6db74">&#34;, b =&#34;</span>, b)
</span></span><span style="display:flex;"><span><span style="color:#75715e">#&gt; Final parameters: a = 1.0100316381654681 , b = 0.9705057604684978</span>
</span></span></code></pre></div><p>最后得到模型 $y_{pred} = 1.01*x+0.97$, 把 $x = [1, 2, 3, 4]$，带到模型中得到$y_{pred}=[1.98,2.99,4.00,5.01]$,跟输出值$y = [2, 3, 4, 5]$是非常接近的。</p>
<p>现在我们明白了如何通过梯度下降法训练一个简单的线性模型，在后面训练神经网络时也是通过梯度下降法和它的变种来训练的。在下一章我们会开始了解神经网络的结构。</p>

    </div>
    <div class="post-footer">
      
    </div>
  </article>

    </main>
  </body>
</html>
